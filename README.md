# 📌 Image Caption Generator - Comparative Analysis of Caption Generation Models  

This project involved a **comparative analysis** of three state-of-the-art image captioning models: **BLIP, Git, and Vit GPT-2**. The goal was to determine the most effective model for **generating high-quality captions** for football-related images.  

## 🔹 Dataset  
- **10,000 images** from a football dataset.  
- **100,000 captions** paired with images for training and evaluation.  

## 🔍 Model Evaluation & Fine-Tuning  
1. **Fine-tuned BLIP, Git, and Vit GPT-2** models using the dataset to enhance caption generation accuracy.  
2. Evaluated models based on **caption quality, relevance, and coherence**.  
3. Measured performance improvements after fine-tuning.  

## 🚀 Key Results  
✅ **BLIP model outperformed Git and Vit GPT-2**, achieving:  
   - **15% improvement** in caption generation accuracy.  
   - **67% reduction in captioning errors** when using a **pre-trained BLIP model**, compared to baseline models.  

✅ **Model Selection**  
   - The **BLIP model** was selected as the **optimal choice** due to its superior performance in generating **accurate, context-aware captions**.  

## 📌 Conclusion  
This analysis demonstrated the effectiveness of **fine-tuning** in improving captioning models. The **BLIP model** showed significant improvements over alternative models, making it the **preferred choice** for high-accuracy image captioning.  
